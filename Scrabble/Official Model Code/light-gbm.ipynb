{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7077941,"sourceType":"datasetVersion","datasetId":4077005}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T17:52:32.329454Z","iopub.execute_input":"2023-12-01T17:52:32.330120Z","iopub.status.idle":"2023-12-01T17:52:32.786309Z","shell.execute_reply.started":"2023-12-01T17:52:32.330081Z","shell.execute_reply":"2023-12-01T17:52:32.785142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n\ndf = pd.read_excel(r\"/kaggle/input/all-metrics/All_metrics.xlsx\")\ndf.rename(columns={\"hist_player_score\": \"hist_player_performance\"}, inplace=True)\ndf.index = df.game_id\ndf","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:52:36.702378Z","iopub.execute_input":"2023-12-01T17:52:36.703497Z","iopub.status.idle":"2023-12-01T17:54:10.547990Z","shell.execute_reply.started":"2023-12-01T17:52:36.703451Z","shell.execute_reply":"2023-12-01T17:54:10.546657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:54:10.550480Z","iopub.execute_input":"2023-12-01T17:54:10.551217Z","iopub.status.idle":"2023-12-01T17:54:10.563107Z","shell.execute_reply.started":"2023-12-01T17:54:10.551173Z","shell.execute_reply":"2023-12-01T17:54:10.561717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Drop 'game_id'\ndf = df.drop('game_id', axis=1)\n\n# Set binary column based on 'first' values\ndf['first_bot'] = df['first'].isin([\"HastyBot\", \"BetterBot\", \"STEEBot\"]).astype(int)\ndf = df.drop('first', axis=1)\n\n# One-hot encode categorical columns\ncategorical_columns = ['time_control_name', 'game_end_reason', 'lexicon', 'rating_mode', 'Bot_nickname']\ndf = pd.get_dummies(df, columns=categorical_columns)\n\n# Drop 'Player_nickname' and 'created_at'\ndf = df.drop(['Player_nickname', 'created_at', \"Bot_game\"], axis=1)\n\n# Move 'Player_rating' to the last column\ncols = [col for col in df.columns if col != 'Player_rating'] + ['Player_rating']\ndf = df[cols]\n\ndf","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:54:10.565376Z","iopub.execute_input":"2023-12-01T17:54:10.565833Z","iopub.status.idle":"2023-12-01T17:54:11.441421Z","shell.execute_reply.started":"2023-12-01T17:54:10.565784Z","shell.execute_reply":"2023-12-01T17:54:11.438145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df[df[\"Player_rating\"].isnull()==False]\ntest = df[df[\"Player_rating\"].isnull()==True]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:54:11.444856Z","iopub.execute_input":"2023-12-01T17:54:11.445370Z","iopub.status.idle":"2023-12-01T17:54:11.469221Z","shell.execute_reply.started":"2023-12-01T17:54:11.445328Z","shell.execute_reply":"2023-12-01T17:54:11.467802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:54:11.471037Z","iopub.execute_input":"2023-12-01T17:54:11.471454Z","iopub.status.idle":"2023-12-01T17:54:11.477299Z","shell.execute_reply.started":"2023-12-01T17:54:11.471419Z","shell.execute_reply":"2023-12-01T17:54:11.475855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n\n# Assuming df is your DataFrame\nX = df.drop('Player_rating', axis=1)  # Features\ny = df['Player_rating']  # Target variable\n\n# Initialize the Random Forest Regressor\nrf_model = RandomForestRegressor(random_state=42)\n\n# Fit the model to the data\nrf_model.fit(X, y)\n\n# Get feature importances\nfeature_importances = rf_model.feature_importances_\n\n# Create a DataFrame to store the results\nfeature_importance_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance in descending order\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# Print the sorted DataFrame\nprint(feature_importance_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:54:11.479656Z","iopub.execute_input":"2023-12-01T17:54:11.480187Z","iopub.status.idle":"2023-12-01T17:56:12.499457Z","shell.execute_reply.started":"2023-12-01T17:54:11.480146Z","shell.execute_reply":"2023-12-01T17:56:12.498320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features = feature_importance_df[feature_importance_df['Importance'] > 0.005]\n\n# Sort the DataFrame by importance in descending order\nselected_features = selected_features.sort_values(by='Importance', ascending=False)\n\n# Print the sorted DataFrame\nselected_features","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:56:12.500971Z","iopub.execute_input":"2023-12-01T17:56:12.501834Z","iopub.status.idle":"2023-12-01T17:56:12.515984Z","shell.execute_reply.started":"2023-12-01T17:56:12.501793Z","shell.execute_reply":"2023-12-01T17:56:12.514910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming df is your original DataFrame\nselected_feature_names = selected_features['Feature'].tolist()\n\n# Select columns with the important features\ndf_selected = df[selected_feature_names + ['Player_rating']]\n\n# Display the selected DataFrame\ndf_selected.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:56:12.517557Z","iopub.execute_input":"2023-12-01T17:56:12.517971Z","iopub.status.idle":"2023-12-01T17:56:12.551221Z","shell.execute_reply.started":"2023-12-01T17:56:12.517905Z","shell.execute_reply":"2023-12-01T17:56:12.550328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.metrics import make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Assuming df_selected is your DataFrame\nX = df_selected.drop('Player_rating', axis=1)\ny = df_selected['Player_rating']\n\n# Create a pipeline with LightGBM\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('lgbm', LGBMRegressor())\n])\n\n# Define parameter grid for grid search\nparam_grid = {\n    'lgbm__n_estimators': [50, 100, 200],\n    'lgbm__max_depth': [6, 8, 12, 15],\n    'lgbm__learning_rate': [0.01, 0.1, 0.2],\n    'lgbm__min_child_samples': [5, 10, 20],\n    'lgbm__subsample': [0.8, 0.9, 1.0],\n    'lgbm__colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n# Define RMSE as the scoring metric for GridSearchCV\nrmse_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(np.mean((y_true - y_pred)**2)))\n\n# Initialize GridSearchCV with verbose set to a positive integer\ngrid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring=rmse_scorer, n_jobs=-1, verbose=2)\n\n# Fit the model using partial_fit to print live progress\ngrid_search.fit(X, y)\n\n# Get the best parameters\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n\n# Get the best model\nbest_model = grid_search.best_estimator_\nprint(\"\\nBest Model:\", best_model)\n\n# Get cross-validation scores\nprint(\"\\nRunning cross-validation. This may take some time...\")\nkf = KFold(n_splits=10, shuffle=True, random_state=42)  # Specify the same number of splits as the GridSearchCV\nfold = 1\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    best_model.fit(X_train, y_train)\n    y_pred = best_model.predict(X_test)\n\n    fold_rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n    print(f\"Fold {fold}: RMSE = {fold_rmse}\")\n    fold += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T17:56:12.552624Z","iopub.execute_input":"2023-12-01T17:56:12.552953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_selected = test[selected_feature_names + ['Player_rating']]\n\n# Display the selected DataFrame\ntest_df_selected.head()\n# Assuming df_selected is your DataFrame\ntest_X = test_df_selected.drop('Player_rating', axis=1)\ntest_y = test_df_selected['Player_rating']\n\ntest_X[\"Predictions\"] = best_model.predict(test_X)\ntest_X[\"game_id\"] = test_X.index\ntest_X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\nfile_name = f\"final_test_results_{timestamp}.csv\"\n\n\n\nfinal_test_results = test_X[[\"game_id\", \"Predictions\"]]\nfinal_test_results.rename(columns={\"Predictions\": \"rating\"}, inplace=True)\nfinal_test_results_reset = final_test_results.reset_index(drop=True)\nfinal_test_results_sorted = final_test_results_reset.sort_values(by='game_id', ascending=True)\nfinal_test_results_sorted.to_csv(file_name, index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}